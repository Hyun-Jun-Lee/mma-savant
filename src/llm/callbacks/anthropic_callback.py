import asyncio
import time
from typing import Dict, Any, List
from datetime import datetime

from langchain.callbacks.base import AsyncCallbackHandler
from langchain.schema import LLMResult

from common.utils import utc_now

class AnthropicCallbackHandler(AsyncCallbackHandler):
    """ì‹¤ì œ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬"""
    
    def __init__(self, message_id: str, conversation_id : int):
        self.tokens = []
        self.message_id = message_id
        self.conversation_id = conversation_id
        self.current_content = ""
        self.stream_queue = asyncio.Queue()
        self.is_streaming = False
        self.tool_calls = []
    
    async def on_llm_new_token(self, token: str, **kwargs) -> None:
        """ìƒˆ í† í°ì´ ìƒì„±ë  ë•Œ í˜¸ì¶œ - ì‹¤ì œ ìŠ¤íŠ¸ë¦¬ë°"""
        try:
            token_str = ""
            
            # Anthropicì˜ í† í° í˜•ì‹ ì²˜ë¦¬ ë° íˆ´ í˜¸ì¶œ í† í° í•„í„°ë§
            if isinstance(token, dict):
                # íˆ´ í˜¸ì¶œ ê´€ë ¨ í† í°ë“¤ í•„í„°ë§
                tool_types = ['tool_use', 'input_json_delta', 'tool_call', 'function_call']
                if token.get('type') in tool_types:
                    return  # íˆ´ ê´€ë ¨ í† í°ì€ ìŠ¤íŠ¸ë¦¬ë°í•˜ì§€ ì•ŠìŒ
                
                # íˆ´ í˜¸ì¶œ IDë‚˜ ì´ë¦„ì´ í¬í•¨ëœ í† í° í•„í„°ë§
                if 'id' in token and token.get('id', '').startswith('toolu_'):
                    return
                
                # {'text': 'content', 'type': 'text', 'index': 0} í˜•ì‹
                if 'text' in token:
                    token_str = token['text']
                else:
                    return  # textê°€ ì—†ëŠ” í† í°ì€ ìŠ¤íŠ¸ë¦¬ë°í•˜ì§€ ì•ŠìŒ
                    
            elif isinstance(token, list):
                # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê° ìš”ì†Œì—ì„œ text ì¶”ì¶œ
                texts = []
                for item in token:
                    if isinstance(item, dict):
                        # íˆ´ ê´€ë ¨ í† í° í•„í„°ë§
                        tool_types = ['tool_use', 'input_json_delta', 'tool_call', 'function_call']
                        if item.get('type') in tool_types:
                            continue
                        # íˆ´ ID í† í° í•„í„°ë§
                        if 'id' in item and item.get('id', '').startswith('toolu_'):
                            continue
                        if 'text' in item:
                            texts.append(item['text'])
                    else:
                        texts.append(str(item))
                token_str = ''.join(texts)
                if not token_str:
                    return  # ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ìŠ¤íŠ¸ë¦¬ë°í•˜ì§€ ì•ŠìŒ
            else:
                token_str = str(token)
            
            if token_str:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì²˜ë¦¬
                self.tokens.append(token_str)
                self.current_content += token_str
                
                # ìŠ¤íŠ¸ë¦¬ë° íì— í† í° ì¶”ê°€
                await self.stream_queue.put({
                    "type": "content",
                    "content": token_str,
                    "message_id": self.message_id,
                    "conversation_id": self.conversation_id,
                    "timestamp": utc_now().isoformat()
                })
                
        except Exception as e:
            print(f"âŒ Error in on_llm_new_token: {e}")
            print(f"ğŸ” Token type: {type(token)}, value: {token}")
    
    async def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs) -> None:
        """LLM ì‹œì‘ ì‹œ í˜¸ì¶œ"""
        self.tokens = []
        self.current_content = ""
        self.is_streaming = True
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì‹ í˜¸
        await self.stream_queue.put({
            "type": "start",
            "message_id": self.message_id,
            "conversation_id": self.conversation_id,
            "timestamp": utc_now().isoformat()
        })
    
    async def on_llm_end(self, response: LLMResult, **kwargs) -> None:
        """LLM ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
        self.is_streaming = False
        
        # ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ ì‹ í˜¸
        await self.stream_queue.put({
            "type": "end",
            "message_id": self.message_id,
            "conversation_id": self.conversation_id,
            "timestamp": utc_now().isoformat(),
            "final_content": self.current_content
        })
    
    async def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs) -> None:
        """íˆ´ ì‹œì‘ ì‹œ í˜¸ì¶œ"""
        tool_name = serialized.get("name", "unknown")
        tool_start_time = time.time()
        self.tool_calls.append({
            "tool": tool_name,
            "input": input_str,
            "status": "started",
            "start_time": tool_start_time
        })
        
        print(f"ğŸ”§ Tool '{tool_name}' started at {tool_start_time}")
        
        # íˆ´ ì‚¬ìš© ì•Œë¦¼
        await self.stream_queue.put({
            "type": "tool_start",
            "tool_name": tool_name,
            "tool_input": input_str,
            "message_id": self.message_id,
            "conversation_id": self.conversation_id,
            "timestamp": utc_now().isoformat()
        })
    
    async def on_tool_end(self, output: str, **kwargs) -> None:
        """íˆ´ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
        tool_end_time = time.time()
        
        if self.tool_calls:
            tool_call = self.tool_calls[-1]
            tool_call["status"] = "completed"
            tool_call["result"] = output[:200] + "..." if len(output) > 200 else output
            tool_call["end_time"] = tool_end_time
            
            # íˆ´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            if "start_time" in tool_call:
                tool_duration = tool_end_time - tool_call["start_time"]
                tool_call["duration"] = tool_duration
                print(f"ğŸ”§ Tool '{tool_call['tool']}' completed in {tool_duration:.3f}s")
            else:
                print(f"ğŸ”§ Tool completed at {tool_end_time}")
        
        # íˆ´ ì™„ë£Œ ì•Œë¦¼
        await self.stream_queue.put({
            "type": "tool_end",
            "tool_result": output[:200] + "..." if len(output) > 200 else output,
            "message_id": self.message_id,
            "conversation_id": self.conversation_id,
            "timestamp": utc_now().isoformat()
        })
    
    async def on_agent_action(self, action, **kwargs) -> None:
        """ì—ì´ì „íŠ¸ ì•¡ì…˜ ì‹œ í˜¸ì¶œ"""
        await self.stream_queue.put({
            "type": "thinking",
            "thought": f"Using tool: {action.tool}",
            "message_id": self.message_id,
            "conversation_id": self.conversation_id,
            "timestamp": utc_now().isoformat()
        })

def get_anthropic_callback_handler(message_id: str, conversation_id : int):
    return AnthropicCallbackHandler(message_id=message_id, conversation_id=conversation_id)
