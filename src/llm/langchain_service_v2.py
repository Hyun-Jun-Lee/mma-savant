"""
LangChain ê¸°ë°˜ LLM ì„œë¹„ìŠ¤ V2 - ë¦¬íŒ©í† ë§ëœ ë²„ì „
ëª¨ë“ˆí™”ëœ ì•„í‚¤í…ì²˜ë¡œ ë‹¤ì–‘í•œ LLM í”„ë¡œë°”ì´ë” ì§€ì› ë° í–¥ìƒëœ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""
import os
import asyncio
import uuid
import time
from typing import List, Dict, Any, Optional, AsyncGenerator
from datetime import datetime
from traceback import format_exc

from langchain_core.messages import AIMessage, HumanMessage

from config import Config
from llm.model_factory import create_llm_with_callbacks, get_available_providers
from llm.agent_manager_v2 import AgentManagerV2
from llm.stream_processor import (
    extract_safe_text_content, 
    clean_response_content,
    create_final_result,
    create_error_response,
    validate_streaming_chunk
)
from common.utils import remove_timestamps_from_tool_result
from llm.performance_monitor import setup_langsmith_tracing
from conversation.message_manager import ChatHistoryManager
from database.connection.postgres_conn import get_async_db_context
from common.logging_config import get_logger
from common.utils import kr_time_now

LOGGER = get_logger(__name__)


class LangChainLLMService:
    """
    LangChain LLM ì„œë¹„ìŠ¤ V2 - ëª¨ë“ˆí™”ëœ ì•„í‚¤í…ì²˜
    """
    
    def __init__(self, max_cache_size: int = 100, provider: Optional[str] = None):
        """
        ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            max_cache_size: íˆìŠ¤í† ë¦¬ ìºì‹œ í¬ê¸°
            provider: ì‚¬ìš©í•  LLM í”„ë¡œë°”ì´ë” (Noneì´ë©´ Configì—ì„œ ê²°ì •)
        """
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° íŠ¸ë ˆì´ì‹± ì„¤ì •
        setup_langsmith_tracing()
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.history_manager = ChatHistoryManager(
            async_db_session_factory=get_async_db_context,
            max_cache_size=max_cache_size
        )
        
        self.agent_manager = AgentManagerV2()
        
        # LLM í”„ë¡œë°”ì´ë” ì„¤ì •
        self.provider = provider or Config.LLM_PROVIDER
    
    async def generate_streaming_chat_response(
        self,
        user_message: str,
        session_id: Optional[str] = None,
        user_id: Optional[int] = None,
        provider_override: Optional[str] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì‘ë‹µ ìƒì„±
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            session_id: ì„¸ì…˜ ID
            user_id: ì‚¬ìš©ì ID
            provider_override: í”„ë¡œë°”ì´ë” ì˜¤ë²„ë¼ì´ë“œ
        
        Yields:
            Dict[str, Any]: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²­í¬ë“¤
        """
        # í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜ ê²€ì¦
        if not session_id:
            LOGGER.error("Session ID is required for streaming chat response")
            yield create_error_response(
                ValueError("Session ID is required"),
                "unknown",
                "unknown"
            )
            return

        if not user_id:
            LOGGER.error("User ID is required for streaming chat response")
            yield create_error_response(
                ValueError("User ID is required"),
                "unknown",
                session_id
            )
            return

        message_id = str(uuid.uuid4())
        start_time = time.time()
        
        # LangSmith ë©”íƒ€ë°ì´í„° ì„¤ì •
        langsmith_metadata = {
            "user_id": user_id,
            "session_id": session_id,
            "message_id": message_id,
            "service": "mma-savant",
            "version": "2.0",
            "start_time": kr_time_now().isoformat()
        }
        
        # LangSmith ë©”íƒ€ë°ì´í„° ì¤€ë¹„ (ìë™ìœ¼ë¡œ ì¶”ì ë¨)
        if Config.LANGCHAIN_TRACING_V2:
            LOGGER.debug(f"LangSmith metadata prepared: {langsmith_metadata}")
        
        try:
            
            # 1. ì±„íŒ… íˆìŠ¤í† ë¦¬ ë¡œë“œ
            try:
                history_start = time.time()
                history = await self.history_manager.get_session_history(session_id, user_id)
                history_time = time.time() - history_start
                LOGGER.info(f"â±ï¸ History loading: {history_time:.3f}s")
                LOGGER.info(f"ğŸ“š Loaded {len(history.messages)} messages from cache")
                
            except Exception as e:
                LOGGER.error(f"âŒ Error loading chat history: {e}")
                LOGGER.error(format_exc())
                
                yield {
                    "type": "error",
                    "error": f"Failed to load chat history: {str(e)}",
                    "message_id": message_id,
                    "session_id": session_id,
                    "timestamp": kr_time_now().isoformat()
                }
                return
            
            # 2. MCP ë„êµ¬ ë¡œë“œ ë° LLM ì„¤ì •
            try:
                mcp_start = time.time()
                async with self.agent_manager.get_mcp_tools() as tools:
                    mcp_time = time.time() - mcp_start
                    LOGGER.info(f"â±ï¸ MCP tools loading took: {mcp_time:.3f}s")
                    LOGGER.info(f"ğŸ”§ Loaded {len(tools)} MCP tools")
                    
                    # Two-Phase ì‹œìŠ¤í…œ ì„¤ì •
                    try:
                        # LLM ë° ì½œë°± ìƒì„±
                        selected_provider = provider_override or self.provider
                        llm, callback_handler = create_llm_with_callbacks(
                            message_id=message_id,
                            session_id=session_id,
                            provider=selected_provider
                        )
                        LOGGER.info(f"ğŸ¤– Using provider for Two-Phase: {selected_provider}")
                        
                        # íˆìŠ¤í† ë¦¬ ê²€ì¦
                        valid_chat_history = self.agent_manager.validate_chat_history(history.messages)
                        LOGGER.info(f"ğŸ“š Using {len(valid_chat_history)} valid messages for Two-Phase context")
                        LOGGER.info(f"ğŸ”§ Two-Phase system ready with {len(tools)} MCP tools")
                        
                    except Exception as e:
                        LOGGER.error(f"âŒ Error setting up Two-Phase system: {e}")
                        LOGGER.error(format_exc())
                        yield {
                            "type": "error",
                            "error": f"Failed to setup Two-Phase system: {str(e)}",
                            "message_id": message_id,
                            "session_id": session_id,
                            "timestamp": kr_time_now().isoformat(),
                            "two_phase_system": True
                        }
                        return
                
                    # 3. Two-Phase ì‹œìŠ¤í…œ ì‹¤í–‰ ë° ìŠ¤íŠ¸ë¦¬ë°
                    async for chunk in self._execute_two_phase_with_streaming(
                        user_message=user_message,
                        chat_history=valid_chat_history,
                        llm=llm,
                        callback_handler=callback_handler,
                        history=history,
                        message_id=message_id,
                        session_id=session_id,
                        user_id=user_id
                    ):
                        # ì²­í¬ ìœ íš¨ì„± ê²€ì‚¬
                        if validate_streaming_chunk(chunk):
                            yield chunk
                        else:
                            LOGGER.warning(f"âš ï¸ Invalid streaming chunk filtered: {chunk}")
            
            except Exception as e:
                LOGGER.error(f"âŒ Error loading MCP tools: {e}")
                LOGGER.error(format_exc())
                yield {
                    "type": "error",
                    "error": f"Failed to load MCP tools: {str(e)}",
                    "message_id": message_id,
                    "session_id": session_id,
                    "timestamp": kr_time_now().isoformat()
                }
        
        except Exception as e:
            LOGGER.error(f"âŒ Main execution error: {e}")
            LOGGER.error(format_exc())
            yield {
                "type": "error", 
                "error": str(e),
                "message_id": message_id,
                "session_id": session_id,
                "timestamp": kr_time_now().isoformat()
            }
        
        finally:
            # ì´ ì‹¤í–‰ ì‹œê°„ ë¡œê¹…
            total_time = time.time() - start_time
            LOGGER.info(f"â±ï¸ Total streaming function took: {total_time:.3f}s")
            
            # LangSmith ìµœì¢… ë©”íŠ¸ë¦­ ë¡œê¹… (ìë™ìœ¼ë¡œ ì¶”ì ë¨)
            if Config.LANGCHAIN_TRACING_V2:
                final_metrics = {
                    "total_streaming_time": total_time,
                    "message_id": message_id,
                    "session_id": session_id,
                    "user_id": user_id,
                    "completion_status": "success"
                }
                LOGGER.info(f"LangSmith final metrics: {final_metrics}")
    
    async def _execute_two_phase_with_streaming(
        self,
        user_message: str,
        chat_history: List,
        llm,
        callback_handler,
        history,
        message_id: str,
        session_id: str,
        user_id: Optional[int] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        Two-Phase ì‹œìŠ¤í…œ ì‹¤í–‰ ë° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
        """
        phase1_result = None
        phase2_result = None
        final_response = ""
        
        async def run_two_phase():
            nonlocal phase1_result, phase2_result, final_response
            
            try:
                two_phase_start = time.time()
                LOGGER.info("ğŸš€ Starting Two-Phase execution...")
                
                # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                user_msg = HumanMessage(content=user_message)
                history.add_message(user_msg)
                
                # Phase 1: Understanding and Collection
                LOGGER.info("ğŸ“ Phase 1: Understanding and Collection")
                yield {
                    "type": "phase_start",
                    "phase": 1,
                    "description": "Analyzing query and collecting data",
                    "message_id": message_id,
                    "session_id": session_id,
                    "timestamp": kr_time_now().isoformat()
                }
                
                result = await self.agent_manager.process_two_step(
                    user_query=user_message,
                    llm=llm,
                    callback_handler=callback_handler,
                    chat_history=chat_history
                )

                two_phase_time = time.time() - two_phase_start
                LOGGER.info("âœ… Two-Phase execution completed")
                LOGGER.info(f"â±ï¸ Total Two-Phase execution took: {two_phase_time:.3f}s")

                # AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (ì‹œê°í™” ì •ë³´ëŠ” ì €ì¥í•˜ì§€ ì•Šê³  ê°„ë‹¨í•œ ìš”ì•½ë§Œ)
                summary_content = f"MMA ë°ì´í„° ë¶„ì„ ì™„ë£Œ: {result.get('visualization_type', 'unknown')} ì°¨íŠ¸, {result.get('row_count', 0)}ê°œ ë°ì´í„°"
                ai_message = AIMessage(
                    content=summary_content,
                    additional_kwargs={
                        "two_phase_system": True,
                        "visualization_type": result.get('visualization_type'),
                        "row_count": result.get('row_count', 0)
                    }
                )
                history.add_message(ai_message)
                LOGGER.info(f"âœ… AI message added to history: {len(summary_content)} chars")

                # ìµœì¢… ê²°ê³¼ ë°˜í™˜ (ê°„ì†Œí™”ëœ ì‘ë‹µì— ìµœì†Œ ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ê°€)
                yield {
                    **result,  # process_two_stepì˜ ê°„ì†Œí™”ëœ ê²°ê³¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    "type": "final_result",
                    "message_id": message_id,
                    "session_id": session_id,
                    "timestamp": kr_time_now().isoformat(),
                    "total_execution_time": two_phase_time
                }
                    
            except Exception as e:
                LOGGER.error(f"âŒ Two-Phase execution failed: {e}")
                LOGGER.error(format_exc())
                
                # Rate limit ì—ëŸ¬ íŠ¹ë³„ ì²˜ë¦¬
                error_message = str(e)
                if "rate_limit_error" in error_message or "429" in error_message:
                    LOGGER.warning("ğŸš« Rate limit exceeded - reducing token usage recommended")
                    error_message = "API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                
                yield {
                    "type": "error",
                    "error": error_message,
                    "message_id": message_id,
                    "session_id": session_id,
                    "timestamp": kr_time_now().isoformat(),
                    "two_phase_system": True,
                    "langsmith_enabled": Config.LANGCHAIN_TRACING_V2
                }
        
        # Two-Phase ì‹¤í–‰ ë° ìŠ¤íŠ¸ë¦¬ë°
        try:
            async for chunk in run_two_phase():
                yield chunk
        except Exception as e:
            LOGGER.error(f"âŒ Two-Phase streaming error: {e}")
            yield {
                "type": "error",
                "error": str(e),
                "message_id": message_id,
                "session_id": session_id,
                "timestamp": kr_time_now().isoformat(),
                "two_phase_system": True
            }
    
    def get_conversation_starter(self) -> str:
        """ëŒ€í™” ì‹œì‘ ë©”ì‹œì§€ ë°˜í™˜"""
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œë°”ì´ë”ì— ë”°ë¥¸ ë§ì¶¤ ë©”ì‹œì§€
            available_providers = get_available_providers()
            provider_info = f" (Using {self.provider})" if len(available_providers) > 1 else ""
            
            return f"ì•ˆë…•í•˜ì„¸ìš”! MMA Savantì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤{provider_info}. MMAì— ê´€í•œ ëª¨ë“  ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”!"
            
        except Exception as e:
            LOGGER.error(f"âŒ Error getting conversation starter: {e}")
            return "ì•ˆë…•í•˜ì„¸ìš”! MMAì— ê´€í•œ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
    
    async def health_check(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        try:
            # ê¸°ë³¸ ìƒíƒœ
            health_status = {
                "service": "LangChainLLMServiceV2",
                "status": "healthy",
                "timestamp": kr_time_now().isoformat(),
                "version": "2.0"
            }
            
            # í”„ë¡œë°”ì´ë” ìƒíƒœ
            available_providers = get_available_providers()
            health_status.update({
                "llm_provider": self.provider,
                "available_providers": available_providers,
                "providers_count": len(available_providers)
            })
            
            # Two-Phase ì‹œìŠ¤í…œ ìƒíƒœ
            agent_health = await self.agent_manager.health_check()
            health_status["two_phase_system"] = agent_health
            health_status["agent_manager_version"] = "v2"
            
            # LangSmith ìƒíƒœ
            health_status["langsmith_enabled"] = Config.LANGCHAIN_TRACING_V2
            
            return health_status
            
        except Exception as e:
            LOGGER.error(f"âŒ Health check error: {e}")
            return {
                "service": "LangChainLLMServiceV2",
                "status": "error",
                "error": str(e),
                "timestamp": kr_time_now().isoformat(),
                "two_phase_system": True
            }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # Two-Phase ì‹œìŠ¤í…œ ì •ë¦¬
            if hasattr(self, 'agent_manager'):
                self.agent_manager.clear_tools_cache()
            
            LOGGER.info("âœ… Two-Phase LLM service V2 cleanup completed")
            
        except Exception as e:
            LOGGER.error(f"âŒ Two-Phase cleanup error: {e}")


# ê¸€ë¡œë²Œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
_langchain_service_v2 = None


async def get_langchain_service(
    provider: Optional[str] = None,
    max_cache_size: int = 100
) -> LangChainLLMService:
    """
    ê¸€ë¡œë²Œ LangChain ì„œë¹„ìŠ¤ V2 ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Args:
        provider: LLM í”„ë¡œë°”ì´ë” (ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œì—ë§Œ ì ìš©)
        max_cache_size: ìºì‹œ í¬ê¸° (ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œì—ë§Œ ì ìš©)
    
    Returns:
        LangChainLLMService: ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
    """
    global _langchain_service_v2
    
    if _langchain_service_v2 is None:
        _langchain_service_v2 = LangChainLLMService(
            max_cache_size=max_cache_size,
            provider=provider
        )
        LOGGER.info("âœ… Two-Phase LangChain service V2 created")
    
    return _langchain_service_v2


# í¸ì˜ í•¨ìˆ˜ë“¤
async def create_streaming_response(
    user_message: str,
    session_id: str,
    user_id: int,
    provider: Optional[str] = None
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± í¸ì˜ í•¨ìˆ˜
    
    Args:
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        session_id: ì„¸ì…˜ ID
        user_id: ì‚¬ìš©ì ID
        provider: í”„ë¡œë°”ì´ë” ì˜¤ë²„ë¼ì´ë“œ
    
    Yields:
        Dict[str, Any]: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²­í¬ë“¤
    """
    service = await get_langchain_service(provider=provider)
    
    async for chunk in service.generate_streaming_chat_response(
        user_message=user_message,
        session_id=session_id,
        user_id=user_id,
        provider_override=provider
    ):
        yield chunk


if __name__ == "__main__":
    """í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹…ìš©"""
    import asyncio
    
    async def test_service_v2():
        print("ğŸš€ Two-Phase LangChain Service V2 Test")
        print("=" * 50)
        
        try:
            # ì„œë¹„ìŠ¤ ìƒì„±
            service = await get_langchain_service()
            
            # ìƒíƒœ í™•ì¸
            health = await service.health_check()
            print(f"\nğŸ¥ Health Check:")
            print(f"  Status: {health['status']}")
            print(f"  Provider: {health['llm_provider']}")
            print(f"  Available Providers: {health['available_providers']}")
            
            # ëŒ€í™” ì‹œì‘ ë©”ì‹œì§€
            starter = service.get_conversation_starter()
            print(f"\nğŸ’¬ Conversation Starter:")
            print(f"  {starter}")
            
            print(f"\nâœ… Two-Phase Service V2 test completed successfully")
            
        except Exception as e:
            print(f"\nâŒ Two-Phase Service V2 test failed: {e}")
            import traceback
            traceback.print_exc()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if asyncio.get_event_loop().is_running():
        print("Running in existing event loop - skipping test")
    else:
        asyncio.run(test_service_v2())